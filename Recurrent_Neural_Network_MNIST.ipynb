{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNFMc16uvJveiv4jksErIT0",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shakeeluetp1041/Machine-Learning/blob/main/Recurrent_Neural_Network_MNIST.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ewUXEHhKhbwR",
        "outputId": "c9bb4706-977c-41cd-b924-1dd760224243"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-images-idx3-ubyte.gz to data/MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:01<00:00, 8009839.22it/s] \n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/train-labels-idx1-ubyte.gz to data/MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 521698.12it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/train-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-images-idx3-ubyte.gz to data/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 4309756.05it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-images-idx3-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Failed to download (trying next):\n",
            "HTTP Error 403: Forbidden\n",
            "\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading https://ossci-datasets.s3.amazonaws.com/mnist/t10k-labels-idx1-ubyte.gz to data/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 4225000.84it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/MNIST/raw/t10k-labels-idx1-ubyte.gz to data/MNIST/raw\n",
            "\n",
            "EPOCH: 0, TRAIN LOSS: 0.2810, TRAIN ACCURACY: 91.47,TEST Loss: 0.1543, Test ACCURACY: 95.39\n",
            "EPOCH: 1, TRAIN LOSS: 0.1285, TRAIN ACCURACY: 96.11,TEST Loss: 0.1188, Test ACCURACY: 96.29\n",
            "EPOCH: 2, TRAIN LOSS: 0.1136, TRAIN ACCURACY: 96.58,TEST Loss: 0.1014, Test ACCURACY: 96.96\n",
            "EPOCH: 3, TRAIN LOSS: 0.1017, TRAIN ACCURACY: 97.04,TEST Loss: 0.1095, Test ACCURACY: 96.87\n"
          ]
        }
      ],
      "source": [
        "# Vanilla RNN for MNIST Digit Classification\n",
        "# You can use the same code for GRU, Just replace nn.RNN------>nn.GRU in line 27\n",
        "# You can use the same code for LSTM, Just replace nn.RNN------>nn.LSTM in line 27. Also replace line 32 with 33 by uncommenting\n",
        "\n",
        "import torch\n",
        "from torch.utils.data import DataLoader\n",
        "import torchvision\n",
        "from torchvision import transforms,datasets\n",
        "import matplotlib.pyplot as plt\n",
        "from torch import nn\n",
        "# To remove the directory\n",
        "# import shutil\n",
        "# shutil.rmtree('./data')\n",
        "# Device agnositic code\n",
        "device='cuda' if torch.cuda.is_available() else 'cpu'\n",
        "train_data=torchvision.datasets.MNIST(root='data',train=True,download=True,transform=transforms.ToTensor())\n",
        "test_data=torchvision.datasets.MNIST(root='data',train=False,download=True,transform=transforms.ToTensor())\n",
        "BATCH_SIZE=64\n",
        "train_dataloader=DataLoader(dataset=train_data,batch_size=BATCH_SIZE,shuffle=True)\n",
        "test_dataloader=DataLoader(dataset=test_data,batch_size=BATCH_SIZE,shuffle=False)\n",
        "class RNN(nn.Module):\n",
        "  def __init__(self,inputsize,hidden_size,num_layers,seq_length,num_classes):# No need to define seq_lenth, it can be extracted form the shape of input\n",
        "    super(RNN,self).__init__()\n",
        "    self.hidden_size=hidden_size\n",
        "    self.num_layers=num_layers\n",
        "    self.seq_length=seq_length\n",
        "    self.rnn=nn.RNN(input_size=inputsize,hidden_size=hidden_size,num_layers=num_layers,batch_first=True)\n",
        "    self.fc=nn.Linear(seq_length*hidden_size,num_classes)\n",
        "  def forward(self,x):\n",
        "    h0=torch.zeros(self.num_layers,x.shape[0],self.hidden_size).to(device)\n",
        "    c0=torch.zeros(self.num_layers,x.shape[0],self.hidden_size).to(device)\n",
        "    rnn_output,_=self.rnn(x,h0)      # comment  this for nn.LSTM\n",
        "    # rnn_output,_=self.rnn(x,(h0,c0)) # uncomment this for nn.LSTM\n",
        "\n",
        "    output=rnn_output.reshape(-1,self.seq_length*self.hidden_size)\n",
        "    output=self.fc(output)\n",
        "    return output\n",
        "def accuracy_fn(y_pred,y_true):\n",
        "  count=(y_pred==y_true).sum().item()\n",
        "  acc=count/len(y_true)\n",
        "  return (acc*100)\n",
        "model=RNN(inputsize=28,hidden_size=256,num_layers=2,seq_length=28,num_classes=len(train_data.classes)).to(device)\n",
        "loss_fn=nn.CrossEntropyLoss()\n",
        "optimizer=torch.optim.Adam(model.parameters(),lr=0.001)\n",
        "\n",
        "\n",
        "EPOCHS=4\n",
        "for epoch in range(EPOCHS):\n",
        "  model.train()\n",
        "  train_loss=0\n",
        "  train_acc=0\n",
        "  test_loss=0\n",
        "  test_acc=0\n",
        "  for (X_train,y_train) in train_dataloader:\n",
        "    X_train,y_train=X_train.to(device),y_train.to(device)\n",
        "    train_output=model(X_train.squeeze())\n",
        "    loss=loss_fn(train_output,y_train)\n",
        "    train_loss+=loss\n",
        "    y_train_pred=torch.argmax(train_output,dim=1)\n",
        "    train_acc+=accuracy_fn(y_train_pred,y_train)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "  train_loss/=len(train_dataloader)\n",
        "  train_acc/=len(train_dataloader)\n",
        "  model.eval()\n",
        "  with torch.inference_mode():\n",
        "    for (X_test,y_test) in test_dataloader:\n",
        "      X_test,y_test=X_test.to(device),y_test.to(device)\n",
        "      test_output=model(X_test.squeeze())\n",
        "      loss=loss_fn(test_output,y_test)\n",
        "      test_loss+=loss\n",
        "      y_test_pred=torch.argmax(test_output,dim=1)\n",
        "      test_acc+=accuracy_fn(y_test_pred,y_test)\n",
        "    test_loss/=len(test_dataloader)\n",
        "    test_acc/=len(test_dataloader)\n",
        "  print(f'EPOCH: {epoch}, TRAIN LOSS: {train_loss:.4f}, TRAIN ACCURACY: {train_acc:.2f},TEST Loss: {test_loss:.4f}, Test ACCURACY: {test_acc:.2f}')\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2XMHojUlh089"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}